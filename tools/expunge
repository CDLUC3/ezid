#! /usr/bin/env python

# Expunges expired test identifiers.  Identifiers are read from a noid
# database or from the EZID store database.  Usage:
#
#   expunge {dbpath|-}
#     dbpath: noid database pathname (.bdb)
#
#   expunge dbpath -p [azbocrtke]
#     print/debug mode; argument is one or more flags:
#     a: print all entries (a=z+b)
#     z: print all non-identifier entries
#     b: print all identifier bindings (b=o+c)
#     o: print bindings other than _c
#     c: print _c bindings (c=r+t)
#     r: print _c bindings of real (non-test) identifiers
#     t: print _c bindings of test identifiers (t=k+e)
#     k: print _c bindings of test identifiers to be kept
#     e: print _c bindings of expired test identifiers
#
# The URL of the noid egg service is read from the EZID configuration
# file, as is the location of the EZID store database.
#
# This script requires several EZID modules.  The PYTHONPATH
# environment variable must include the .../SITE_ROOT/PROJECT_ROOT
# directory; if it doesn't, we attempt to dynamically locate it and
# add it.  The DJANGO_SETTINGS_MODULE environment variable must be
# set; if it isn't, we set it to "settings.production".
#
# Greg Janee <gjanee@ucop.edu>
# April 2011

import bsddb.db
import os
import re
import sys
import time

if "DJANGO_SETTINGS_MODULE" not in os.environ:
  os.environ["DJANGO_SETTINGS_MODULE"] = "settings.production"

try:
  import settings
except ImportError:
  sys.path.append(os.path.split(os.path.split(
    os.path.abspath(__file__))[0])[0])
  import settings

# Bootstrapping: reference a(ny) Django setting to trigger the loading
# of said settings, which causes the PYTHONPATH to be modified,
# supporting subsequent imports.
import django.conf
django.conf.settings.PROJECT_ROOT

# Configure the logging so that errors don't get added to the server's
# log file.  Also, disable daemon threads.
django.conf.settings.LOGGING_CONFIG_FILE = "logging.offline.conf"
django.conf.settings.DAEMON_THREADS_ENABLED = False

import config
import datacite
import noid_egg
import search
import store
import util

testArkPrefix = config.config("shoulders.ark_test")[5:]
testDoiPrefix = util.doi2shadow(config.config("shoulders.doi_test")[4:])
lifetime = 2*7*24*60*60 # seconds

usageText = """Usage:

  expunge {dbpath|-}
    dbpath: noid database pathname (.bdb)

  expunge dbpath -p [azbocrtke]
    print/debug mode; argument is one or more flags:
    a: print all entries (a=z+b)
    z: print all non-identifier entries
    b: print all identifier bindings (b=o+c)
    o: print bindings other than _c
    c: print _c bindings (c=r+t)
    r: print _c bindings of real (non-test) identifiers
    t: print _c bindings of test identifiers (t=k+e)
    k: print _c bindings of test identifiers to be kept
    e: print _c bindings of expired test identifiers
"""

if len(sys.argv) == 2:
  dbPath = sys.argv[1] if sys.argv[1] != "-" else None
  debug = ""
elif len(sys.argv) == 4 and sys.argv[2] == "-p" and\
  re.match("[azbocrtke]+$", sys.argv[3]):
  dbPath = sys.argv[1]
  debug = sys.argv[3]
  for f, ff in [("a", "zb"), ("b", "oc"), ("c", "rt"), ("t", "ke")]:
    if f in debug: debug += ff
else:
  sys.stderr.write(usageText)
  sys.exit(1)

def output (flag, k, v):
  if flag in debug: print k, "->", v

expungeList = []
shadowedId = {}
status = {}
group = {}

if dbPath:
  db = bsddb.db.DB()
  db.open(dbPath, flags=bsddb.db.DB_RDONLY)
  cursor = db.cursor()
  entry = cursor.first()
  while entry != None:
    k, v = entry
    if "|" not in k:
      output("z", k, v)
    else:
      id, label = k.split("|", 1)
      if util.validateArk(id) != id:
        output("z", k, v)
      elif label != "_c" or not re.match("[0-9]+$", v):
        if label == "_s":
          shadowedId[id] = util.decode(v)
        elif label == "_is":
          status[id] = util.decode(v)
        elif label == "_g":
          group[id] = util.decode(v)
        output("o", k, v)
      elif not id.startswith(testArkPrefix) and\
        not id.startswith(testDoiPrefix):
        output("r", k, v)
      else:
        creationTime = int(v)
        if int(time.time())-creationTime < lifetime:
          output("k", k, v)
        else:
          output("e", k, v)
          expungeList.append(id)
    entry = cursor.next()
  db.close()
else:
  lastId = ""
  while True:
    ids = store.harvest(start=lastId, maximum=1000)
    if len(ids) == 0: break
    for id, m in ids:
      if (id.startswith(testArkPrefix) or id.startswith(testDoiPrefix)) and\
        int(time.time())-int(m["_c"]) >= lifetime:
        expungeList.append(id)
        group[id] = m["_g"]
        if "_is" in m: status[id] = m["_is"]
        if "_s" in m: shadowedId[id] = m["_s"]
    lastId = ids[-1][0]

if debug == "":
  for id in expungeList:
    try:
      # We can't actually delete a DOI.  As the next best thing, we
      # set its target URL to an "invalid identifier" page.
      if id.startswith(testDoiPrefix) and\
        status.get(id, "public") != "reserved":
        doi = shadowedId[id]
        assert doi.startswith("doi:")
        datacite.setTargetUrl(doi[4:], "http://datacite.org/invalidDOI")
      noid_egg.deleteIdentifier(id)
      store.delete(id)
      if group[id] != "anonymous":
        if id.startswith(testArkPrefix):
          qid = "ark:/" + id
        elif id.startswith(testDoiPrefix):
          qid = shadowedId[id]
        else:
          assert False
        search.delete(qid)
    except Exception:
      sys.stderr.write("expunge: processing %s\n" % id)
      raise
